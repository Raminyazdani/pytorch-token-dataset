Ramin Yazdani | pytorch-token-dataset | main | feat(core): Implement complete TokenDataset with padding

Completed the TokenDataset implementation with full functionality:
- Load JSON data with token arrays and labels in __init__
- Calculate and store max sequence length for padding
- Implement __len__ to return dataset size
- Implement __getitem__ with automatic padding to max length
- Convert data to PyTorch tensors for compatibility

Added demonstration cells showing how to:
- Instantiate the dataset from JSON file
- Access individual items
- Integrate with PyTorch DataLoader for batching
- Split data into train/validation sets

This provides a production-ready custom Dataset class that handles variable-length sequences elegantly through automatic padding, making it suitable for training sequence models.
