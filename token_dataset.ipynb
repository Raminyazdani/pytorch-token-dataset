{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a1ee9e1a-17d8-4376-a821-0853f26bb20c",
      "metadata": {
        "id": "a1ee9e1a-17d8-4376-a821-0853f26bb20c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342e79b4",
      "metadata": {
        "id": "342e79b4"
      },
      "source": [
        "The following two cells are a suggestion on accessing the files. You are free to ignore these!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6180270-7ef2-4f8b-9979-d207ce098a29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6180270-7ef2-4f8b-9979-d207ce098a29",
        "outputId": "c35e2812-0084-4007-d526-7e017bc11aa9"
      },
      "outputs": [],
      "source": [
        "with open(\"data.json\", \"r\") as f:\n",
        "    data_1 = json.load(f)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc9fa6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bc9fa6e",
        "outputId": "aefa64d8-6a5e-4c5b-b9c0-9ea5b9f0baa8"
      },
      "outputs": [],
      "source": [
        "with open(\"data.csv\", \"r\") as file:\n",
        "    for row in csv.DictReader(file):\n",
        "        print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ad227bf3-112d-403b-88a7-1a0bbdfece7f",
      "metadata": {
        "id": "ad227bf3-112d-403b-88a7-1a0bbdfece7f"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import List, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, data_path: str = None, data: List[Tuple[np.ndarray, int]] = None, max_length: int = 50):\n",
        "        \"\"\"\n",
        "        Custom dataset class for loading and processing JSON data or using preprocessed data.\n",
        "\n",
        "        Parameters:\n",
        "        - data_path: path to the JSON file (only used if `data` is not provided)\n",
        "        - data: list of preprocessed (padded_tokens, label) tuples (optional)\n",
        "        - max_length: max length for padding sequences (only used if loading from JSON)\n",
        "        \"\"\"\n",
        "        if data is not None:\n",
        "            # Use preprocessed data directly\n",
        "            self.data = data\n",
        "        else:\n",
        "            # Load and preprocess data from JSON\n",
        "            with open(data_path, \"r\") as f:\n",
        "                raw_data = json.load(f)\n",
        "            self.data = []\n",
        "            for item in raw_data:\n",
        "                tokens = np.array(item[\"tokens\"])\n",
        "                padded_tokens = np.zeros(max_length, dtype=int)\n",
        "                length = min(len(tokens), max_length)\n",
        "                padded_tokens[:length] = tokens[:length]\n",
        "                label = item[\"label\"]\n",
        "                self.data.append((padded_tokens, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Get a single sample from the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - idx: index of the sample to retrieve\n",
        "\n",
        "        Returns:\n",
        "        - Tuple of (padded tokens, label) as torch Tensors\n",
        "        \"\"\"\n",
        "        tokens, label = self.data[idx]\n",
        "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return tokens, label\n",
        "\n",
        "class TokenDataLoader(DataLoader):\n",
        "    def __init__(self, dataset: TokenDataset, batch_size: int = 32, shuffle: bool = True):\n",
        "        \"\"\"\n",
        "        Custom data loader for batching data from TokenDataset, subclassing PyTorch's DataLoader.\n",
        "\n",
        "        Parameters:\n",
        "        - dataset: TokenDataset instance\n",
        "        - batch_size: number of samples per batch\n",
        "        - shuffle: whether to shuffle data each epoch\n",
        "        \"\"\"\n",
        "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "33765577-f46c-410a-b04f-3ecbf983e82a",
      "metadata": {
        "id": "33765577-f46c-410a-b04f-3ecbf983e82a"
      },
      "outputs": [],
      "source": [
        "# Load the dataset from JSON\n",
        "data_path = \"data.json\"\n",
        "dataset = TokenDataset(data_path=data_path, max_length=50)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create subsets for training and testing data\n",
        "train_data = [dataset[i] for i in train_indices]\n",
        "test_data = [dataset[i] for i in test_indices]\n",
        "\n",
        "# Create TokenDataset instances for training and testing data\n",
        "train_dataset = TokenDataset(data=train_data)\n",
        "test_dataset = TokenDataset(data=test_data)\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "train_loader = TokenDataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = TokenDataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "OBm3UghSZPtU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBm3UghSZPtU",
        "outputId": "f2fbf299-5130-43c2-bd8a-d3fa3b95adeb"
      },
      "outputs": [],
      "source": [
        "# Display the first batch from the training loader\n",
        "for batch_inputs, batch_labels in train_loader:\n",
        "    print(\"Training Batch Inputs:\", batch_inputs)\n",
        "    print(\"Training Batch Labels:\", batch_labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a46ef4d6",
      "metadata": {
        "id": "a46ef4d6"
      },
      "source": [
        "Test correctness here (do not change the cell below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8386581e-416c-435b-84f9-f4ccf8a5c00f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8386581e-416c-435b-84f9-f4ccf8a5c00f",
        "outputId": "cec135f7-ab20-4a46-ec04-510034ff62dd"
      },
      "outputs": [],
      "source": [
        "X, y = next(iter(train_loader))\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "19278914-52c8-4484-8bf7-fd4d9bdc3ad0",
      "metadata": {
        "id": "19278914-52c8-4484-8bf7-fd4d9bdc3ad0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class CSVDataset(Dataset):\n",
        "    def __init__(self, csv_path: str, indices: list = None):\n",
        "        \"\"\"\n",
        "        Custom dataset class for loading and processing CSV data.\n",
        "\n",
        "        Parameters:\n",
        "        - csv_path: path to the CSV file\n",
        "        - indices: subset of indices to use (for train/test split)\n",
        "        \"\"\"\n",
        "        # Load the CSV data\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "\n",
        "        # Extract features (symptoms) and labels (prognosis)\n",
        "        self.features = self.data.drop(columns=[\"prognosis\"]).values.astype(np.float32)\n",
        "        self.labels = self.data[[\"prognosis\"]].values\n",
        "\n",
        "        # One-hot encode the prognosis labels\n",
        "        self.encoder = OneHotEncoder(sparse_output=False)\n",
        "        self.encoded_labels = self.encoder.fit_transform(self.labels)\n",
        "\n",
        "        # Apply indices if provided (for train/test splits)\n",
        "        if indices is not None:\n",
        "            self.features = self.features[indices]\n",
        "            self.encoded_labels = self.encoded_labels[indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Get a single sample from the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - idx: index of the sample to retrieve\n",
        "\n",
        "        Returns:\n",
        "        - Tuple of (features, encoded label) as torch Tensors\n",
        "        \"\"\"\n",
        "        features = torch.tensor(self.features[idx])\n",
        "        label = torch.tensor(self.encoded_labels[idx])\n",
        "        return features, label\n",
        "\n",
        "\n",
        "class CSVDataLoader(DataLoader):\n",
        "    def __init__(self, dataset: CSVDataset, batch_size: int = 32, shuffle: bool = True):\n",
        "        \"\"\"\n",
        "        Custom data loader for batching data from CSVDataset, subclassing PyTorch's DataLoader.\n",
        "\n",
        "        Parameters:\n",
        "        - dataset: CSVDataset instance\n",
        "        - batch_size: number of samples per batch\n",
        "        - shuffle: whether to shuffle data each epoch\n",
        "        \"\"\"\n",
        "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c485899-0fe1-4cba-ae1b-a3c68c8f65f2",
      "metadata": {
        "id": "4c485899-0fe1-4cba-ae1b-a3c68c8f65f2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the dataset\n",
        "csv_path = \"data.csv\"\n",
        "full_dataset = CSVDataset(csv_path=csv_path)\n",
        "\n",
        "# Split indices for training and testing\n",
        "train_indices, test_indices = train_test_split(list(range(len(full_dataset))), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create training and testing datasets\n",
        "train_dataset = CSVDataset(csv_path=csv_path, indices=train_indices)\n",
        "test_dataset = CSVDataset(csv_path=csv_path, indices=test_indices)\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "train_loader = CSVDataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = CSVDataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dUbMcwR3azq9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUbMcwR3azq9",
        "outputId": "940c12a7-c369-472e-a248-b91032b0a86b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Batch Inputs: tensor([[270.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [ 62.,   1.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [330.,   1.,   0.,  ...,   0.,   0.,   0.],\n",
            "        ...,\n",
            "        [ 48.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
            "        [288.,   0.,   1.,  ...,   0.,   0.,   0.],\n",
            "        [447.,   0.,   1.,  ...,   0.,   0.,   0.]])\n",
            "Training Batch Labels: tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Display the first batch from the training loader\n",
        "for batch_inputs, batch_labels in train_loader:\n",
        "    print(\"Training Batch Inputs:\", batch_inputs)\n",
        "    print(\"Training Batch Labels:\", batch_labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71947ef",
      "metadata": {
        "id": "f71947ef"
      },
      "source": [
        "Test correctness here (do not change the cell below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "82343dbf-a775-472a-a263-282589271f9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82343dbf-a775-472a-a263-282589271f9e",
        "outputId": "1db7281e-ae33-4fd2-9db4-0bef547d1105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 65])\n",
            "torch.Size([32, 11])\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(train_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}